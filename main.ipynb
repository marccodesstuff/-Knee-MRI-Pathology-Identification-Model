{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3108eaa5",
   "metadata": {},
   "source": [
    "# Xception CNN Model for Knee Pathology Detection\n",
    "This notebook demonstrates how to create and train an Xception CNN model to detect knee pathologies using DICOM files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d149773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd63c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "data_dir = 'output_folder'\n",
    "#image_size = (368, 640)\n",
    "batch_size = 32\n",
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771aa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DICOM Files in Batches:  65%|██████▍   | 296/458 [03:58<02:55,  1.08s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Updated preprocess_dicom_files function to handle variable image shapes\n",
    "def preprocess_dicom_files(data_dir, batch_size=100):\n",
    "    files_list = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                files_list.append(os.path.join(root, file))\n",
    "\n",
    "    num_files = len(files_list)\n",
    "    images = []  # Use a list to store images dynamically\n",
    "    labels = []\n",
    "\n",
    "    for i in tqdm(range(0, num_files, batch_size), desc=\"Processing DICOM Files in Batches\"):\n",
    "        batch_files = files_list[i:i+batch_size]\n",
    "        for file_path in batch_files:\n",
    "            dicom = pydicom.dcmread(file_path)\n",
    "            image = dicom.pixel_array.astype(np.float32)  # Convert to float32\n",
    "            image = image / 255.0  # Normalize pixel values\n",
    "            images.append(image)  # Append image to the list\n",
    "\n",
    "            # Extract label from file naming convention\n",
    "            label = int(os.path.basename(file_path).split('_')[0][4:])\n",
    "            labels.append(label)\n",
    "\n",
    "    # Keep images as a list to handle variable shapes\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "\n",
    "    num_classes = len(np.unique(labels))\n",
    "    print(f\"Number of classes detected: {num_classes}\")\n",
    "\n",
    "    return images, labels, num_classes\n",
    "\n",
    "# Generate data and visualize progress\n",
    "images, labels, num_classes = preprocess_dicom_files(data_dir)\n",
    "\n",
    "# Show dataset shape\n",
    "print(f\"Total images: {len(images)}, Image shapes: {[img.shape for img in images]}\")\n",
    "\n",
    "# Data Generator with tqdm for batch iteration\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(validation_split=0.2)\n",
    "data_generator = datagen.flow(\n",
    "    images,\n",
    "    labels,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Data generator is ready. Starting training now!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976370bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Define the path to the output_folder\n",
    "output_folder = 'output_folder'\n",
    "annotations = pd.read_csv('annotation.csv')  # Load your annotations CSV file\n",
    "\n",
    "# Define the path for saving the .npy file\n",
    "segmentation_data_file = 'segmentation_data.npy'\n",
    "\n",
    "# Check if the .npy file already exists\n",
    "if os.path.exists(segmentation_data_file):\n",
    "    # Load the segmentation data from the .npy file\n",
    "    segmentation_data = np.load(segmentation_data_file, allow_pickle=True)\n",
    "    print(f\"✅ Loaded segmentation data from {segmentation_data_file}\")\n",
    "else:\n",
    "    # Prepare dataset\n",
    "    segmentation_data = []\n",
    "    files_list = [f for f in os.listdir(output_folder) if f.endswith('.dcm')]\n",
    "\n",
    "    # Using tqdm to track progress\n",
    "    for filename in tqdm(files_list, desc=\"Processing DICOM Segmentation\"):\n",
    "        filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Read the DICOM file\n",
    "        dicom_file = pydicom.dcmread(filepath)\n",
    "        pixel_array = dicom_file.pixel_array\n",
    "        height, width = pixel_array.shape\n",
    "\n",
    "        # Create an empty mask\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        # Extract file ID and slice number\n",
    "        try:\n",
    "            file_id = filename.split('_')[0]\n",
    "            slice_number = int(filename.split('_')[1].split('.')[0])  # Ensure slice_number is an integer\n",
    "\n",
    "            # Get corresponding annotations\n",
    "            file_annotations = annotations[\n",
    "                (annotations['file'] == file_id) & (annotations['slice'] == slice_number)\n",
    "            ]\n",
    "\n",
    "            # Draw bounding boxes on the mask\n",
    "            for _, row in file_annotations.iterrows():\n",
    "                x, y, box_width, box_height = (\n",
    "                    int(row['x']),  # Ensure x is an integer\n",
    "                    int(row['y']),  # Ensure y is an integer\n",
    "                    int(row['width']),  # Ensure width is an integer\n",
    "                    int(row['height'])  # Ensure height is an integer\n",
    "                )\n",
    "                mask[y:y + box_height, x:x + box_width] = 1  # Mark region as foreground\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "        # Append to segmentation data\n",
    "        segmentation_data.append({\n",
    "            'image': pixel_array,\n",
    "            'mask': mask\n",
    "        })\n",
    "\n",
    "    # Save the segmentation data to a .npy file\n",
    "    np.save(segmentation_data_file, segmentation_data)\n",
    "    print(f\"✅ Saved segmentation data to {segmentation_data_file}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"✅ Total segmentation samples: {len(segmentation_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Segmentation Masks During Model Training with Cross-Validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, val_index in kf.split(segmentation_data):\n",
    "    print(f'Training on fold {fold_no}...')\n",
    "    \n",
    "    # Split the segmentation data into training and validation sets\n",
    "    train_data = [segmentation_data[i] for i in train_index]\n",
    "    val_data = [segmentation_data[i] for i in val_index]\n",
    "    \n",
    "    X_train = np.array([data['image'] for data in train_data]).reshape(-1, image_size[0], image_size[1], 1)\n",
    "    y_train = np.array([data['mask'] for data in train_data]).reshape(-1, image_size[0], image_size[1], 1)\n",
    "    X_val = np.array([data['image'] for data in val_data]).reshape(-1, image_size[0], image_size[1], 1)\n",
    "    y_val = np.array([data['mask'] for data in val_data]).reshape(-1, image_size[0], image_size[1], 1)\n",
    "    \n",
    "    # Load Pre-trained Xception Model\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Freeze Base Model Layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile the Model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the Model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=10,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(f'Fold {fold_no} completed.')\n",
    "    fold_no += 1\n",
    "\n",
    "# Save the final model\n",
    "model.save('xception_knee_segmentation_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
