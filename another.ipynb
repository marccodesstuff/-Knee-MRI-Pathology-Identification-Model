{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e3b48df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize # Using scikit-image for resizing\n",
    "\n",
    "# Keras / TensorFlow Components\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense, Dropout, GlobalMaxPooling1D, Lambda ,concatenate)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# Scikit-learn for evaluation\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, roc_curve\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa5c64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Plane: sagittal\n",
      "Model will be saved to: ./output_models/xception_mrnet_sagittal_best.h5\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set these paths according to your MRNet dataset location\n",
    "BASE_DATA_DIR = './dataset/' # Base directory of the extracted MRNet dataset\n",
    "OUTPUT_DIR = './output_models/' # Where to save trained models and logs\n",
    "\n",
    "# Select the plane to train on\n",
    "# Options: 'axial', 'coronal', 'sagittal'\n",
    "PLANE = 'sagittal'\n",
    "\n",
    "# Model & Training Hyperparameters\n",
    "IMG_SIZE = (299, 299) # Input size for Xception\n",
    "N_CHANNELS = 3 # Xception expects 3 channels (we'll stack grayscale)\n",
    "BATCH_SIZE = 4 # <<< Adjust based on GPU memory (can be small like 2 or 4)\n",
    "EPOCHS = 25 # Max number of training epochs (EarlyStopping will likely stop it sooner)\n",
    "LEARNING_RATE = 1e-4 # Initial learning rate for Adam optimizer\n",
    "DROPOUT_RATE = 0.5 # Dropout rate for the classification head\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Construct model save path based on the chosen plane\n",
    "MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, f'xception_mrnet_{PLANE}_best.h5')\n",
    "print(f\"Selected Plane: {PLANE}\")\n",
    "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ab5524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs detected. Running on CPU (will be very slow).\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"Successfully configured memory growth for {len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(f\"Error setting memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPUs detected. Running on CPU (will be very slow).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5527da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_dir, task, split):\n",
    "    \"\"\"Loads labels for a specific task (acl, meniscus) and split (train, valid).\"\"\"\n",
    "    label_path = os.path.join(label_dir, f\"{split}-{task}.csv\")\n",
    "    try:\n",
    "        labels_df = pd.read_csv(label_path, header=None, names=['exam_id', 'label'], dtype={'exam_id': str})\n",
    "        # Filter out rows with non-integer labels\n",
    "        labels_df = labels_df[pd.to_numeric(labels_df['label'], errors='coerce').notnull()]\n",
    "        labels_df['label'] = labels_df['label'].astype(int)  # Convert to integer\n",
    "        labels_df.set_index('exam_id', inplace=True)\n",
    "        print(f\"Loaded {len(labels_df)} labels for {task} - {split} split.\")\n",
    "        return labels_df['label'].to_dict()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Label file not found at {label_path}\")\n",
    "        return {}\n",
    "\n",
    "def preprocess_slice(slice_img, target_size=(299, 299)):\n",
    "    \"\"\"Preprocesses a single 2D slice: resizes, normalizes, and stacks to 3 channels.\"\"\"\n",
    "    # Ensure input is float for calculations\n",
    "    slice_img = slice_img.astype(np.float32)\n",
    "\n",
    "    # 1. Resize\n",
    "    # Note: anti_aliasing=True is generally recommended but can be slower.\n",
    "    # You might need `pip install scikit-image`\n",
    "    slice_resized = resize(slice_img, target_size, anti_aliasing=True, preserve_range=True) # preserve_range=True is important before custom norm\n",
    "\n",
    "    # 2. Normalize (Example: Scale to [0, 1] based on slice intensity)\n",
    "    # The MRNet paper used scan-specific Z-score normalization, which might be better.\n",
    "    # This simple scaling is easier to implement initially.\n",
    "    min_val = np.min(slice_resized)\n",
    "    max_val = np.max(slice_resized)\n",
    "    if max_val > min_val:\n",
    "        slice_normalized = (slice_resized - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        slice_normalized = np.zeros(target_size) # Handle blank slices\n",
    "\n",
    "    # 3. Stack to 3 Channels for Xception input\n",
    "    slice_3channel = np.stack([slice_normalized] * 3, axis=-1)\n",
    "\n",
    "    return slice_3channel.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75df18c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRNetSequence(Sequence):\n",
    "    \"\"\" Keras Sequence for loading MRNet data slice by slice. \"\"\"\n",
    "    def __init__(self, data_dir, plane, labels_acl, labels_meniscus, exam_ids, batch_size, target_size, is_train=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.plane = plane\n",
    "        self.labels_acl = labels_acl\n",
    "        self.labels_meniscus = labels_meniscus\n",
    "        # Ensure exam_ids are strings to match dictionary keys\n",
    "        self.exam_ids = [str(eid) for eid in exam_ids]\n",
    "        self.batch_size = batch_size # Note: this is exam batch size\n",
    "        self.target_size = target_size\n",
    "        self.is_train = is_train # Flag to enable shuffling for training data\n",
    "        self.indices = np.arange(len(self.exam_ids))\n",
    "        if self.is_train:\n",
    "            self.shuffle() # Initial shuffle for training\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch (based on exams)\n",
    "        return int(np.ceil(len(self.exam_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices for exams\n",
    "        batch_exam_indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        batch_exam_ids = [self.exam_ids[i] for i in batch_exam_indices]\n",
    "\n",
    "        batch_slices_list = []\n",
    "        batch_labels_acl_list = []\n",
    "        batch_labels_meniscus_list = []\n",
    "\n",
    "        for exam_id in batch_exam_ids:\n",
    "            exam_path = os.path.join(self.data_dir, self.plane, f\"{exam_id}.npy\")\n",
    "            try:\n",
    "                # Load the 3D volume for the exam\n",
    "                volume = np.load(exam_path) # Shape: (num_slices, height, width)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"\\nWarning: File not found {exam_path}. Skipping exam {exam_id}.\")\n",
    "                continue\n",
    "            except ValueError as e:\n",
    "                 print(f\"\\nWarning: Error loading {exam_path}: {e}. Skipping exam {exam_id}.\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "            # Get exam labels (using .get for safety, although IDs should exist)\n",
    "            label_acl = self.labels_acl.get(exam_id)\n",
    "            label_meniscus = self.labels_meniscus.get(exam_id)\n",
    "\n",
    "            if label_acl is None or label_meniscus is None:\n",
    "                print(f\"\\nWarning: Labels not found for exam {exam_id}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Preprocess each slice and collect\n",
    "            num_slices_in_volume = volume.shape[0]\n",
    "            for i in range(num_slices_in_volume):\n",
    "                slice_img = volume[i]\n",
    "                processed_slice = preprocess_slice(slice_img, self.target_size)\n",
    "                batch_slices_list.append(processed_slice)\n",
    "                batch_labels_acl_list.append(label_acl)\n",
    "                batch_labels_meniscus_list.append(label_meniscus)\n",
    "\n",
    "        # Convert lists to numpy arrays for the batch\n",
    "        batch_slices_np = np.array(batch_slices_list)\n",
    "        batch_labels_acl_np = np.array(batch_labels_acl_list, dtype=np.float32)\n",
    "        batch_labels_meniscus_np = np.array(batch_labels_meniscus_list, dtype=np.float32)\n",
    "\n",
    "        # Return batch data in the format Keras expects\n",
    "        # x: batch of slices, y: dictionary matching model output names\n",
    "        return batch_slices_np, {'acl_output': batch_labels_acl_np, 'meniscus_output': batch_labels_meniscus_np}\n",
    "\n",
    "    def shuffle(self):\n",
    "         \"\"\"Shuffles the order of exams\"\"\"\n",
    "         np.random.shuffle(self.indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle exam indices after each epoch if this is for training\n",
    "        if self.is_train:\n",
    "            self.shuffle()\n",
    "            # print(\"\\nShuffled training exam indices for next epoch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a47937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xception_model(input_shape, num_classes_acl=1, num_classes_meniscus=1, dropout_rate=0.5):\n",
    "    \"\"\"Builds the Xception model for slice-level prediction with two output heads.\"\"\"\n",
    "    # --- Base Model (Xception) ---\n",
    "    # include_top=False: Remove the original ImageNet classification layer\n",
    "    # pooling=None: We'll add our own pooling after the base model\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape, pooling=None)\n",
    "\n",
    "    # --- Freeze Base Model Layers ---\n",
    "    # Start by freezing the pre-trained weights. We'll only train the new layers initially.\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # --- Input Layer ---\n",
    "    # Define the input tensor matching the preprocessed slice shape\n",
    "    slice_input = Input(shape=input_shape, name=\"slice_input\")\n",
    "\n",
    "    # --- Connect Input to Base Model ---\n",
    "    # Pass the input through the base model.\n",
    "    # training=False is crucial here when base_model is frozen, to ensure BatchNorm layers run in inference mode.\n",
    "    x = base_model(slice_input, training=False)\n",
    "\n",
    "    # --- Pooling Layer (Per Slice) ---\n",
    "    # Apply Global Average Pooling to the output features of the base model for each slice.\n",
    "    # This reduces spatial dimensions to a single feature vector per slice.\n",
    "    x = GlobalAveragePooling2D(name=\"slice_gap\")(x)\n",
    "\n",
    "    # --- Classification Head ---\n",
    "    # Add Dropout for regularization before the final Dense layers\n",
    "    x = Dropout(dropout_rate, name=\"head_dropout\")(x)\n",
    "\n",
    "    # Output layer for ACL Tear classification (Sigmoid for binary probability)\n",
    "    acl_output = Dense(num_classes_acl, activation='sigmoid', name='acl_output')(x)\n",
    "\n",
    "    # Output layer for Meniscus Tear classification (Sigmoid for binary probability)\n",
    "    # This head branches off from the same pooled & dropout features.\n",
    "    meniscus_output = Dense(num_classes_meniscus, activation='sigmoid', name='meniscus_output')(x)\n",
    "\n",
    "    # --- Create and Return Model ---\n",
    "    # Define the model with one input (slice_input) and two outputs (acl_output, meniscus_output)\n",
    "    model = Model(inputs=slice_input, outputs=[acl_output, meniscus_output], name=f\"Xception_MRNet_{PLANE}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b0d1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_aggregated(model, data_dir, plane, labels_acl, labels_meniscus, exam_ids, target_size):\n",
    "    \"\"\"Evaluates the slice-level model using exam-level aggregation (Max Pooling).\"\"\"\n",
    "    true_labels_acl = []\n",
    "    true_labels_meniscus = []\n",
    "    pred_probs_acl = []\n",
    "    pred_probs_meniscus = []\n",
    "\n",
    "    print(f\"\\nStarting exam-level evaluation on {len(exam_ids)} exams using plane '{plane}'...\")\n",
    "    progbar = tf.keras.utils.Progbar(len(exam_ids))\n",
    "\n",
    "    # Ensure exam_ids are strings\n",
    "    exam_ids = [str(eid) for eid in exam_ids]\n",
    "\n",
    "    for i, exam_id in enumerate(exam_ids):\n",
    "        exam_path = os.path.join(data_dir, plane, f\"{exam_id}.npy\")\n",
    "        try:\n",
    "            volume = np.load(exam_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Eval File not found {exam_path}. Skipping exam {exam_id}.\")\n",
    "            progbar.update(i + 1) # Update progress bar even if skipped\n",
    "            continue\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Error loading eval file {exam_path}: {e}. Skipping exam {exam_id}.\")\n",
    "            progbar.update(i + 1)\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Get true labels for the exam\n",
    "        label_acl = labels_acl.get(exam_id)\n",
    "        label_meniscus = labels_meniscus.get(exam_id)\n",
    "\n",
    "        if label_acl is None or label_meniscus is None:\n",
    "            print(f\"Warning: Eval Labels not found for exam {exam_id}. Skipping.\")\n",
    "            progbar.update(i + 1)\n",
    "            continue\n",
    "\n",
    "        # Process all slices in the volume\n",
    "        exam_slices_processed = []\n",
    "        num_slices_in_volume = volume.shape[0]\n",
    "        if num_slices_in_volume == 0:\n",
    "             print(f\"Warning: Exam {exam_id} has 0 slices. Skipping.\")\n",
    "             progbar.update(i + 1)\n",
    "             continue\n",
    "\n",
    "        for slice_idx in range(num_slices_in_volume):\n",
    "            processed_slice = preprocess_slice(volume[slice_idx], target_size)\n",
    "            exam_slices_processed.append(processed_slice)\n",
    "\n",
    "        # Stack slices into a batch for prediction\n",
    "        exam_slices_np = np.array(exam_slices_processed)\n",
    "\n",
    "        # Get slice-level predictions from the model\n",
    "        # model.predict yields a list [preds_acl, preds_meniscus]\n",
    "        # each element has shape (num_slices, 1)\n",
    "        slice_preds = model.predict(exam_slices_np, batch_size=len(exam_slices_np), verbose=0)\n",
    "        slice_preds_acl = slice_preds[0].flatten() # Shape: (num_slices,)\n",
    "        slice_preds_meniscus = slice_preds[1].flatten() # Shape: (num_slices,)\n",
    "\n",
    "        # --- Aggregation Step (Max Pooling) ---\n",
    "        # Take the maximum probability across all slices for this exam\n",
    "        exam_pred_prob_acl = np.max(slice_preds_acl) if len(slice_preds_acl) > 0 else 0.5 # Default to 0.5 if no slices\n",
    "        exam_pred_prob_meniscus = np.max(slice_preds_meniscus) if len(slice_preds_meniscus) > 0 else 0.5\n",
    "\n",
    "        # Store results\n",
    "        true_labels_acl.append(label_acl)\n",
    "        true_labels_meniscus.append(label_meniscus)\n",
    "        pred_probs_acl.append(exam_pred_prob_acl)\n",
    "        pred_probs_meniscus.append(exam_pred_prob_meniscus)\n",
    "\n",
    "        progbar.update(i + 1) # Update progress bar\n",
    "\n",
    "    # --- Calculate Metrics ---\n",
    "    print(\"\\n--- Aggregated Evaluation Results ---\")\n",
    "    if not true_labels_acl: # Check if any exams were successfully processed\n",
    "         print(\"No valid exams found or processed for evaluation.\")\n",
    "         return None, None # Return None for AUCs if no data\n",
    "\n",
    "    # Convert lists to numpy arrays for sklearn metrics\n",
    "    true_labels_acl = np.array(true_labels_acl)\n",
    "    true_labels_meniscus = np.array(true_labels_meniscus)\n",
    "    pred_probs_acl = np.array(pred_probs_acl)\n",
    "    pred_probs_meniscus = np.array(pred_probs_meniscus)\n",
    "\n",
    "    # Calculate predicted labels based on 0.5 threshold for Accuracy\n",
    "    pred_labels_acl = (pred_probs_acl > 0.5).astype(int)\n",
    "    pred_labels_meniscus = (pred_probs_meniscus > 0.5).astype(int)\n",
    "\n",
    "    # Calculate AUC, Accuracy, Log Loss for each task\n",
    "    auc_acl = roc_auc_score(true_labels_acl, pred_probs_acl)\n",
    "    acc_acl = accuracy_score(true_labels_acl, pred_labels_acl)\n",
    "    loss_acl = log_loss(true_labels_acl, pred_probs_acl)\n",
    "\n",
    "    auc_meniscus = roc_auc_score(true_labels_meniscus, pred_probs_meniscus)\n",
    "    acc_meniscus = accuracy_score(true_labels_meniscus, pred_labels_meniscus)\n",
    "    loss_meniscus = log_loss(true_labels_meniscus, pred_probs_meniscus)\n",
    "\n",
    "    # Calculate the average AUC (primary MRNet metric)\n",
    "    avg_auc = (auc_acl + auc_meniscus) / 2.0\n",
    "\n",
    "    print(f\"Results for Plane: {plane}\")\n",
    "    print(f\"ACL Task:\")\n",
    "    print(f\"  AUC:      {auc_acl:.4f}\")\n",
    "    print(f\"  Accuracy: {acc_acl:.4f} (Threshold 0.5)\")\n",
    "    print(f\"  Log Loss: {loss_acl:.4f}\")\n",
    "    print(f\"Meniscus Task:\")\n",
    "    print(f\"  AUC:      {auc_meniscus:.4f}\")\n",
    "    print(f\"  Accuracy: {acc_meniscus:.4f} (Threshold 0.5)\")\n",
    "    print(f\"  Log Loss: {loss_meniscus:.4f}\")\n",
    "    print(f\"-----------------------------\")\n",
    "    print(f\"Average Exam AUC: {avg_auc:.4f}\")\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # Return calculated metrics (optional)\n",
    "    results = {\n",
    "        'acl': {'auc': auc_acl, 'acc': acc_acl, 'loss': loss_acl, 'true': true_labels_acl, 'pred_prob': pred_probs_acl},\n",
    "        'meniscus': {'auc': auc_meniscus, 'acc': acc_meniscus, 'loss': loss_meniscus, 'true': true_labels_meniscus, 'pred_prob': pred_probs_meniscus},\n",
    "        'avg_auc': avg_auc\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d00cc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels...\n",
      "Loaded 1130 labels for acl - train split.\n",
      "Loaded 1130 labels for meniscus - train split.\n",
      "Loaded 120 labels for acl - valid split.\n",
      "Loaded 120 labels for meniscus - valid split.\n",
      "\n",
      "Found 1130 training exams for plane sagittal.\n",
      "Found 120 validation exams for plane sagittal.\n",
      "\n",
      "Creating data generators...\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = os.path.join(BASE_DATA_DIR, 'train')\n",
    "valid_data_dir = os.path.join(BASE_DATA_DIR, 'valid')\n",
    "label_dir = BASE_DATA_DIR # Assuming label CSVs are in the base directory\n",
    "\n",
    "# --- Load Labels ---\n",
    "print(\"Loading labels...\")\n",
    "train_labels_acl = load_labels(label_dir, 'acl', 'train')\n",
    "train_labels_meniscus = load_labels(label_dir, 'meniscus', 'train')\n",
    "valid_labels_acl = load_labels(label_dir, 'acl', 'valid')\n",
    "valid_labels_meniscus = load_labels(label_dir, 'meniscus', 'valid')\n",
    "\n",
    "# --- Get Exam IDs ---\n",
    "# Assumes exam IDs are the filenames without the .npy extension\n",
    "# Use chosen PLANE to list files\n",
    "try:\n",
    "    train_exam_ids = sorted([f.split('.')[0] for f in os.listdir(os.path.join(train_data_dir, PLANE)) if f.endswith('.npy')])\n",
    "    valid_exam_ids = sorted([f.split('.')[0] for f in os.listdir(os.path.join(valid_data_dir, PLANE)) if f.endswith('.npy')])\n",
    "    print(f\"\\nFound {len(train_exam_ids)} training exams for plane {PLANE}.\")\n",
    "    print(f\"Found {len(valid_exam_ids)} validation exams for plane {PLANE}.\")\n",
    "    # Simple validation: Check if first few IDs exist in loaded labels\n",
    "    if train_exam_ids and (train_exam_ids[0] not in train_labels_acl or train_exam_ids[0] not in train_labels_meniscus):\n",
    "         print(f\"Warning: Mismatch detected between file IDs (e.g., {train_exam_ids[0]}) and label IDs. Check load_labels and file names.\")\n",
    "    if valid_exam_ids and (valid_exam_ids[0] not in valid_labels_acl or valid_exam_ids[0] not in valid_labels_meniscus):\n",
    "         print(f\"Warning: Mismatch detected between file IDs (e.g., {valid_exam_ids[0]}) and label IDs.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nError: Could not find data directory for plane '{PLANE}' in {train_data_dir} or {valid_data_dir}.\")\n",
    "    print(\"Please ensure BASE_DATA_DIR is correct and contains 'train'/'valid' subfolders with '{PLANE}' subfolders.\")\n",
    "    # Stop execution if data isn't found\n",
    "    raise\n",
    "\n",
    "# --- Create Data Generators ---\n",
    "print(\"\\nCreating data generators...\")\n",
    "train_gen = MRNetSequence(train_data_dir, PLANE, train_labels_acl, train_labels_meniscus,\n",
    "                          train_exam_ids, BATCH_SIZE, IMG_SIZE, is_train=True)\n",
    "\n",
    "valid_gen = MRNetSequence(valid_data_dir, PLANE, valid_labels_acl, valid_labels_meniscus,\n",
    "                          valid_exam_ids, BATCH_SIZE, IMG_SIZE, is_train=False) # is_train=False for validation (no shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model...\n",
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Xception_MRNet_sagittal\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Xception_MRNet_sagittal\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ slice_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ xception            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │ slice_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ slice_gap           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ xception[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ head_dropout        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ slice_gap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ acl_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ head_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meniscus_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ head_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ slice_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ xception            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │ \u001b[38;5;34m20,861,480\u001b[0m │ slice_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ slice_gap           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ xception[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ head_dropout        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ slice_gap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ acl_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m2,049\u001b[0m │ head_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meniscus_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m2,049\u001b[0m │ head_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,865,578</span> (79.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,865,578\u001b[0m (79.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> (16.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,098\u001b[0m (16.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up callbacks...\n",
      "\n",
      "--- Starting Training for sagittal plane ---\n",
      "Epochs: 25, Batch Size (Exams): 4, Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marc Velasquez\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.7707 - acl_output_auc_acl: 0.5015 - acl_output_loss: 0.5417 - loss: 1.2259 - meniscus_output_acc_meniscus: 0.5714 - meniscus_output_auc_meniscus: 0.5100 - meniscus_output_loss: 0.6829\n",
      "Epoch 1: val_loss improved from inf to 1.56463, saving model to ./output_models/xception_mrnet_sagittal_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2156s\u001b[0m 8s/step - acl_output_acc_acl: 0.7708 - acl_output_auc_acl: 0.5015 - acl_output_loss: 0.5416 - loss: 1.2257 - meniscus_output_acc_meniscus: 0.5715 - meniscus_output_auc_meniscus: 0.5100 - meniscus_output_loss: 0.6829 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.5556 - val_acl_output_loss: 0.8638 - val_loss: 1.5646 - val_meniscus_output_acc_meniscus: 0.5405 - val_meniscus_output_auc_meniscus: 0.6013 - val_meniscus_output_loss: 0.6955 - learning_rate: 1.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.8205 - acl_output_auc_acl: 0.5133 - acl_output_loss: 0.4810 - loss: 1.1342 - meniscus_output_acc_meniscus: 0.6349 - meniscus_output_auc_meniscus: 0.5592 - meniscus_output_loss: 0.6504\n",
      "Epoch 2: val_loss improved from 1.56463 to 1.52405, saving model to ./output_models/xception_mrnet_sagittal_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2029s\u001b[0m 7s/step - acl_output_acc_acl: 0.8205 - acl_output_auc_acl: 0.5133 - acl_output_loss: 0.4810 - loss: 1.1343 - meniscus_output_acc_meniscus: 0.6348 - meniscus_output_auc_meniscus: 0.5592 - meniscus_output_loss: 0.6504 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.5992 - val_acl_output_loss: 0.8573 - val_loss: 1.5240 - val_meniscus_output_acc_meniscus: 0.5583 - val_meniscus_output_auc_meniscus: 0.6357 - val_meniscus_output_loss: 0.6661 - learning_rate: 1.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.8110 - acl_output_auc_acl: 0.5269 - acl_output_loss: 0.4917 - loss: 1.1387 - meniscus_output_acc_meniscus: 0.6213 - meniscus_output_auc_meniscus: 0.5926 - meniscus_output_loss: 0.6456\n",
      "Epoch 3: val_loss did not improve from 1.52405\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2024s\u001b[0m 7s/step - acl_output_acc_acl: 0.8110 - acl_output_auc_acl: 0.5270 - acl_output_loss: 0.4917 - loss: 1.1387 - meniscus_output_acc_meniscus: 0.6213 - meniscus_output_auc_meniscus: 0.5927 - meniscus_output_loss: 0.6456 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.6312 - val_acl_output_loss: 0.8927 - val_loss: 1.5603 - val_meniscus_output_acc_meniscus: 0.5588 - val_meniscus_output_auc_meniscus: 0.6520 - val_meniscus_output_loss: 0.6654 - learning_rate: 1.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.8191 - acl_output_auc_acl: 0.5360 - acl_output_loss: 0.4803 - loss: 1.1124 - meniscus_output_acc_meniscus: 0.6393 - meniscus_output_auc_meniscus: 0.6200 - meniscus_output_loss: 0.6299\n",
      "Epoch 4: val_loss improved from 1.52405 to 1.48502, saving model to ./output_models/xception_mrnet_sagittal_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2023s\u001b[0m 7s/step - acl_output_acc_acl: 0.8191 - acl_output_auc_acl: 0.5361 - acl_output_loss: 0.4803 - loss: 1.1125 - meniscus_output_acc_meniscus: 0.6393 - meniscus_output_auc_meniscus: 0.6200 - meniscus_output_loss: 0.6300 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.6639 - val_acl_output_loss: 0.8254 - val_loss: 1.4850 - val_meniscus_output_acc_meniscus: 0.5758 - val_meniscus_output_auc_meniscus: 0.6610 - val_meniscus_output_loss: 0.6567 - learning_rate: 1.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.7877 - acl_output_auc_acl: 0.5641 - acl_output_loss: 0.5104 - loss: 1.1560 - meniscus_output_acc_meniscus: 0.6290 - meniscus_output_auc_meniscus: 0.6281 - meniscus_output_loss: 0.6369\n",
      "Epoch 5: val_loss did not improve from 1.48502\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2018s\u001b[0m 7s/step - acl_output_acc_acl: 0.7878 - acl_output_auc_acl: 0.5641 - acl_output_loss: 0.5103 - loss: 1.1558 - meniscus_output_acc_meniscus: 0.6291 - meniscus_output_auc_meniscus: 0.6281 - meniscus_output_loss: 0.6369 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.6805 - val_acl_output_loss: 0.8413 - val_loss: 1.4911 - val_meniscus_output_acc_meniscus: 0.5943 - val_meniscus_output_auc_meniscus: 0.6681 - val_meniscus_output_loss: 0.6484 - learning_rate: 1.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.8411 - acl_output_auc_acl: 0.5638 - acl_output_loss: 0.4395 - loss: 1.0708 - meniscus_output_acc_meniscus: 0.6347 - meniscus_output_auc_meniscus: 0.6414 - meniscus_output_loss: 0.6292\n",
      "Epoch 6: val_loss improved from 1.48502 to 1.40483, saving model to ./output_models/xception_mrnet_sagittal_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2012s\u001b[0m 7s/step - acl_output_acc_acl: 0.8410 - acl_output_auc_acl: 0.5639 - acl_output_loss: 0.4396 - loss: 1.0709 - meniscus_output_acc_meniscus: 0.6347 - meniscus_output_auc_meniscus: 0.6414 - meniscus_output_loss: 0.6292 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7037 - val_acl_output_loss: 0.7577 - val_loss: 1.4048 - val_meniscus_output_acc_meniscus: 0.6039 - val_meniscus_output_auc_meniscus: 0.6734 - val_meniscus_output_loss: 0.6439 - learning_rate: 1.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.8090 - acl_output_auc_acl: 0.5970 - acl_output_loss: 0.4787 - loss: 1.1082 - meniscus_output_acc_meniscus: 0.6412 - meniscus_output_auc_meniscus: 0.6407 - meniscus_output_loss: 0.6241\n",
      "Epoch 7: val_loss did not improve from 1.40483\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2010s\u001b[0m 7s/step - acl_output_acc_acl: 0.8090 - acl_output_auc_acl: 0.5970 - acl_output_loss: 0.4787 - loss: 1.1082 - meniscus_output_acc_meniscus: 0.6412 - meniscus_output_auc_meniscus: 0.6407 - meniscus_output_loss: 0.6241 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7079 - val_acl_output_loss: 0.8095 - val_loss: 1.4677 - val_meniscus_output_acc_meniscus: 0.5850 - val_meniscus_output_auc_meniscus: 0.6775 - val_meniscus_output_loss: 0.6529 - learning_rate: 1.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.8360 - acl_output_auc_acl: 0.5885 - acl_output_loss: 0.4402 - loss: 1.0647 - meniscus_output_acc_meniscus: 0.6426 - meniscus_output_auc_meniscus: 0.6632 - meniscus_output_loss: 0.6204\n",
      "Epoch 8: val_loss did not improve from 1.40483\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2015s\u001b[0m 7s/step - acl_output_acc_acl: 0.8359 - acl_output_auc_acl: 0.5885 - acl_output_loss: 0.4403 - loss: 1.0648 - meniscus_output_acc_meniscus: 0.6426 - meniscus_output_auc_meniscus: 0.6632 - meniscus_output_loss: 0.6205 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7178 - val_acl_output_loss: 0.7856 - val_loss: 1.4359 - val_meniscus_output_acc_meniscus: 0.5973 - val_meniscus_output_auc_meniscus: 0.6812 - val_meniscus_output_loss: 0.6455 - learning_rate: 1.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acl_output_acc_acl: 0.8192 - acl_output_auc_acl: 0.6047 - acl_output_loss: 0.4607 - loss: 1.0838 - meniscus_output_acc_meniscus: 0.6486 - meniscus_output_auc_meniscus: 0.6577 - meniscus_output_loss: 0.6154\n",
      "Epoch 9: val_loss did not improve from 1.40483\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2023s\u001b[0m 7s/step - acl_output_acc_acl: 0.8192 - acl_output_auc_acl: 0.6047 - acl_output_loss: 0.4607 - loss: 1.0838 - meniscus_output_acc_meniscus: 0.6486 - meniscus_output_auc_meniscus: 0.6577 - meniscus_output_loss: 0.6154 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7207 - val_acl_output_loss: 0.8150 - val_loss: 1.4566 - val_meniscus_output_acc_meniscus: 0.6123 - val_meniscus_output_auc_meniscus: 0.6840 - val_meniscus_output_loss: 0.6389 - learning_rate: 1.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.8219 - acl_output_auc_acl: 0.6277 - acl_output_loss: 0.4578 - loss: 1.0684 - meniscus_output_acc_meniscus: 0.6543 - meniscus_output_auc_meniscus: 0.6576 - meniscus_output_loss: 0.6126\n",
      "Epoch 10: val_loss did not improve from 1.40483\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2036s\u001b[0m 7s/step - acl_output_acc_acl: 0.8219 - acl_output_auc_acl: 0.6276 - acl_output_loss: 0.4578 - loss: 1.0684 - meniscus_output_acc_meniscus: 0.6542 - meniscus_output_auc_meniscus: 0.6576 - meniscus_output_loss: 0.6126 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7301 - val_acl_output_loss: 0.7686 - val_loss: 1.4051 - val_meniscus_output_acc_meniscus: 0.6287 - val_meniscus_output_auc_meniscus: 0.6862 - val_meniscus_output_loss: 0.6338 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.8252 - acl_output_auc_acl: 0.6128 - acl_output_loss: 0.4534 - loss: 1.0673 - meniscus_output_acc_meniscus: 0.6576 - meniscus_output_auc_meniscus: 0.6587 - meniscus_output_loss: 0.6086\n",
      "Epoch 11: val_loss improved from 1.40483 to 1.39783, saving model to ./output_models/xception_mrnet_sagittal_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2054s\u001b[0m 7s/step - acl_output_acc_acl: 0.8252 - acl_output_auc_acl: 0.6129 - acl_output_loss: 0.4534 - loss: 1.0673 - meniscus_output_acc_meniscus: 0.6576 - meniscus_output_auc_meniscus: 0.6587 - meniscus_output_loss: 0.6086 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7342 - val_acl_output_loss: 0.7645 - val_loss: 1.3978 - val_meniscus_output_acc_meniscus: 0.6314 - val_meniscus_output_auc_meniscus: 0.6888 - val_meniscus_output_loss: 0.6309 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.8011 - acl_output_auc_acl: 0.6338 - acl_output_loss: 0.4836 - loss: 1.1032 - meniscus_output_acc_meniscus: 0.6412 - meniscus_output_auc_meniscus: 0.6784 - meniscus_output_loss: 0.6191\n",
      "Epoch 12: val_loss did not improve from 1.39783\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2268s\u001b[0m 8s/step - acl_output_acc_acl: 0.8012 - acl_output_auc_acl: 0.6338 - acl_output_loss: 0.4835 - loss: 1.1032 - meniscus_output_acc_meniscus: 0.6412 - meniscus_output_auc_meniscus: 0.6783 - meniscus_output_loss: 0.6191 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7336 - val_acl_output_loss: 0.8356 - val_loss: 1.4816 - val_meniscus_output_acc_meniscus: 0.6041 - val_meniscus_output_auc_meniscus: 0.6925 - val_meniscus_output_loss: 0.6415 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.8249 - acl_output_auc_acl: 0.6189 - acl_output_loss: 0.4484 - loss: 1.0722 - meniscus_output_acc_meniscus: 0.6503 - meniscus_output_auc_meniscus: 0.6641 - meniscus_output_loss: 0.6159\n",
      "Epoch 13: val_loss did not improve from 1.39783\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2085s\u001b[0m 7s/step - acl_output_acc_acl: 0.8249 - acl_output_auc_acl: 0.6189 - acl_output_loss: 0.4485 - loss: 1.0722 - meniscus_output_acc_meniscus: 0.6503 - meniscus_output_auc_meniscus: 0.6641 - meniscus_output_loss: 0.6159 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7388 - val_acl_output_loss: 0.7938 - val_loss: 1.4251 - val_meniscus_output_acc_meniscus: 0.6331 - val_meniscus_output_auc_meniscus: 0.6933 - val_meniscus_output_loss: 0.6291 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.8254 - acl_output_auc_acl: 0.6516 - acl_output_loss: 0.4407 - loss: 1.0610 - meniscus_output_acc_meniscus: 0.6561 - meniscus_output_auc_meniscus: 0.6502 - meniscus_output_loss: 0.6154\n",
      "Epoch 14: val_loss did not improve from 1.39783\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2102s\u001b[0m 7s/step - acl_output_acc_acl: 0.8254 - acl_output_auc_acl: 0.6515 - acl_output_loss: 0.4408 - loss: 1.0610 - meniscus_output_acc_meniscus: 0.6561 - meniscus_output_auc_meniscus: 0.6503 - meniscus_output_loss: 0.6154 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7401 - val_acl_output_loss: 0.8170 - val_loss: 1.4439 - val_meniscus_output_acc_meniscus: 0.6391 - val_meniscus_output_auc_meniscus: 0.6951 - val_meniscus_output_loss: 0.6260 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.7915 - acl_output_auc_acl: 0.6426 - acl_output_loss: 0.4858 - loss: 1.1109 - meniscus_output_acc_meniscus: 0.6513 - meniscus_output_auc_meniscus: 0.6725 - meniscus_output_loss: 0.6111\n",
      "Epoch 15: val_loss did not improve from 1.39783\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2098s\u001b[0m 7s/step - acl_output_acc_acl: 0.7916 - acl_output_auc_acl: 0.6426 - acl_output_loss: 0.4857 - loss: 1.1108 - meniscus_output_acc_meniscus: 0.6513 - meniscus_output_auc_meniscus: 0.6725 - meniscus_output_loss: 0.6111 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7442 - val_acl_output_loss: 0.7799 - val_loss: 1.4115 - val_meniscus_output_acc_meniscus: 0.6295 - val_meniscus_output_auc_meniscus: 0.6978 - val_meniscus_output_loss: 0.6282 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - acl_output_acc_acl: 0.8193 - acl_output_auc_acl: 0.6376 - acl_output_loss: 0.4561 - loss: 1.0565 - meniscus_output_acc_meniscus: 0.6712 - meniscus_output_auc_meniscus: 0.6703 - meniscus_output_loss: 0.5969\n",
      "Epoch 16: val_loss improved from 1.39783 to 1.39432, saving model to ./output_models/xception_mrnet_sagittal_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2102s\u001b[0m 7s/step - acl_output_acc_acl: 0.8193 - acl_output_auc_acl: 0.6376 - acl_output_loss: 0.4561 - loss: 1.0565 - meniscus_output_acc_meniscus: 0.6712 - meniscus_output_auc_meniscus: 0.6703 - meniscus_output_loss: 0.5969 - val_acl_output_acc_acl: 0.5605 - val_acl_output_auc_acl: 0.7466 - val_acl_output_loss: 0.7691 - val_loss: 1.3943 - val_meniscus_output_acc_meniscus: 0.6432 - val_meniscus_output_auc_meniscus: 0.6978 - val_meniscus_output_loss: 0.6235 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m225/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6:27\u001b[0m 7s/step - acl_output_acc_acl: 0.8355 - acl_output_auc_acl: 0.6434 - acl_output_loss: 0.4306 - loss: 1.0385 - meniscus_output_acc_meniscus: 0.6563 - meniscus_output_auc_meniscus: 0.6820 - meniscus_output_loss: 0.6047"
     ]
    }
   ],
   "source": [
    "# --- Build Model ---\n",
    "print(\"\\nBuilding model...\")\n",
    "model = build_xception_model(input_shape=(*IMG_SIZE, N_CHANNELS),\n",
    "                             dropout_rate=DROPOUT_RATE)\n",
    "\n",
    "# --- Compile Model ---\n",
    "# We have two outputs, so we use a dictionary for losses and metrics.\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss={'acl_output': BinaryCrossentropy(name='acl_loss'),\n",
    "                    'meniscus_output': BinaryCrossentropy(name='meniscus_loss')},\n",
    "              loss_weights={'acl_output': 1.0, 'meniscus_output': 1.0}, # Give equal importance to both tasks\n",
    "              metrics={'acl_output': [AUC(name='auc_acl'), BinaryAccuracy(name='acc_acl')],\n",
    "                       'meniscus_output': [AUC(name='auc_meniscus'), BinaryAccuracy(name='acc_meniscus')]})\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# --- Callbacks ---\n",
    "print(\"\\nSetting up callbacks...\")\n",
    "# Save the best model based on validation loss (sum of both task losses)\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVE_PATH,\n",
    "                             monitor='val_loss', # Monitor the total validation loss\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False, # Save the entire model structure + weights\n",
    "                             mode='min', # Minimize the validation loss\n",
    "                             verbose=1)\n",
    "\n",
    "# Stop training early if validation loss doesn't improve\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=10, # Stop after 10 epochs of no improvement in val_loss\n",
    "                               mode='min',\n",
    "                               restore_best_weights=True, # Load weights from the best epoch found\n",
    "                               verbose=1)\n",
    "\n",
    "# Reduce learning rate if validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2, # Reduce LR by a factor of 5 (lr = lr * 0.2)\n",
    "                              patience=5,  # Reduce LR after 5 epochs of no improvement\n",
    "                              mode='min',\n",
    "                              min_lr=1e-6, # Minimum learning rate\n",
    "                              verbose=1)\n",
    "\n",
    "# --- Train Model ---\n",
    "print(f\"\\n--- Starting Training for {PLANE} plane ---\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch Size (Exams): {BATCH_SIZE}, Learning Rate: {LEARNING_RATE}\")\n",
    "\n",
    "# Check if generators have data\n",
    "if len(train_gen) == 0 or len(valid_gen) == 0:\n",
    "     print(\"\\nError: Training or validation generator is empty. Cannot start training.\")\n",
    "     print(f\"Check if data exists in '{train_data_dir}/{PLANE}' and '{valid_data_dir}/{PLANE}'.\")\n",
    "else:\n",
    "    history = model.fit(train_gen,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_gen,\n",
    "                        callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "                        verbose=1) # Set verbose=1 or 2 to see progress per epoch\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "    # --- Plot Training History ---\n",
    "    if 'history' in locals() and history is not None:\n",
    "        print(\"\\nPlotting training history...\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        # Loss Plot\n",
    "        axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "        axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "        axes[0].set_title(f'{PLANE} - Model Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss (BCE)')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # AUC Plot (Average of ACL and Meniscus AUC)\n",
    "        # Note: Keras history keys might vary slightly based on TF version, check history.history.keys() if needed\n",
    "        train_auc_avg = (np.array(history.history.get('acl_output_auc_acl', history.history.get('auc_acl', 0))) +\n",
    "                         np.array(history.history.get('meniscus_output_auc_meniscus', history.history.get('auc_meniscus', 0)))) / 2.0\n",
    "        val_auc_avg = (np.array(history.history.get('val_acl_output_auc_acl', history.history.get('val_auc_acl', 0))) +\n",
    "                       np.array(history.history.get('val_meniscus_output_auc_meniscus', history.history.get('val_auc_meniscus', 0)))) / 2.0\n",
    "\n",
    "        axes[1].plot(train_auc_avg, label='Train Avg AUC')\n",
    "        axes[1].plot(val_auc_avg, label='Validation Avg AUC')\n",
    "        axes[1].set_title(f'{PLANE} - Model Average AUC')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Average AUC')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Skipping history plots as training did not complete successfully.\")\n",
    "\n",
    "# --- Save Model to H5 File ---\n",
    "print(\"\\nSaving the trained model to H5 file...\")\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf161a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Evaluation ---\n",
    "print(f\"\\n--- Final Evaluation on Validation Set using Best Model ---\")\n",
    "print(f\"Loading best model weights from: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    # Load the model saved by ModelCheckpoint\n",
    "    best_model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
    "    print(\"Best model loaded successfully.\")\n",
    "\n",
    "    # Evaluate using the aggregated evaluation function\n",
    "    validation_results = evaluate_model_aggregated(best_model,\n",
    "                                                   valid_data_dir,\n",
    "                                                   PLANE,\n",
    "                                                   valid_labels_acl,\n",
    "                                                   valid_labels_meniscus,\n",
    "                                                   valid_exam_ids,\n",
    "                                                   IMG_SIZE)\n",
    "\n",
    "    # Optional: Plot ROC Curves for the validation set\n",
    "    if validation_results:\n",
    "        print(\"\\nPlotting ROC Curves for Validation Set...\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "        # ACL ROC\n",
    "        fpr_acl, tpr_acl, _ = roc_curve(validation_results['acl']['true'], validation_results['acl']['pred_prob'])\n",
    "        plt.plot(fpr_acl, tpr_acl, label=f\"ACL (AUC = {validation_results['acl']['auc']:.3f})\")\n",
    "\n",
    "        # Meniscus ROC\n",
    "        fpr_men, tpr_men, _ = roc_curve(validation_results['meniscus']['true'], validation_results['meniscus']['pred_prob'])\n",
    "        plt.plot(fpr_men, tpr_men, label=f\"Meniscus (AUC = {validation_results['meniscus']['auc']:.3f})\")\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Chance') # Diagonal line\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.title(f'ROC Curves - {PLANE} Plane - Validation Set')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Best model file not found at {MODEL_SAVE_PATH}. Evaluation skipped.\")\n",
    "    print(\"This might happen if training was interrupted or did not improve over initial weights.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
