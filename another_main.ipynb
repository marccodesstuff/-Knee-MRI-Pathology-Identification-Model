{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a874582",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "This section imports all the necessary libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense, Dropout,\n",
    "                                     GlobalMaxPooling1D, Lambda, concatenate)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "from skimage.transform import resize # Using scikit-image for resizing\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a50754",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "Set the paths and hyperparameters for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a029d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = './MRNet-v1.0/' # Base directory of the extracted MRNet dataset\n",
    "OUTPUT_DIR = './output_models/' # Where to save trained models and logs\n",
    "\n",
    "IMG_SIZE = (299, 299) # Input size for Xception\n",
    "N_CHANNELS = 3 # Xception expects 3 channels\n",
    "BATCH_SIZE = 8 # Adjust based on GPU memory. Smaller might be needed.\n",
    "EPOCHS = 50 # Number of training epochs (can be adjusted with EarlyStopping)\n",
    "LEARNING_RATE = 1e-4\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a00aa",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "Define utility functions for loading labels, preprocessing slices, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329619fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_dir, task, split):\n",
    "    \"\"\"Loads labels for a specific task (acl, meniscus) and split (train, valid).\"\"\"\n",
    "    label_path = os.path.join(label_dir, f\"{split}-{task}.csv\")\n",
    "    labels_df = pd.read_csv(label_path, header=None, names=['exam_id', 'label'], index_col='exam_id')\n",
    "    return labels_df['label'].to_dict()\n",
    "\n",
    "def preprocess_slice(slice_img, target_size):\n",
    "    \"\"\"Preprocesses a single 2D slice.\"\"\"\n",
    "    slice_resized = resize(slice_img, target_size, anti_aliasing=True)\n",
    "    slice_normalized = (slice_resized - np.min(slice_resized)) / (np.max(slice_resized) - np.min(slice_resized) + 1e-6)\n",
    "    slice_3channel = np.stack([slice_normalized] * 3, axis=-1)\n",
    "    return slice_3channel.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827e61b",
   "metadata": {},
   "source": [
    "# Keras Sequence for Data Loading\n",
    "Define a custom Keras Sequence class for loading MRNet data slice by slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982aebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRNetSequence(Sequence):\n",
    "    def __init__(self, data_dir, plane, labels_acl, labels_meniscus, exam_ids, batch_size, target_size):\n",
    "        self.data_dir = data_dir\n",
    "        self.plane = plane\n",
    "        self.labels_acl = labels_acl\n",
    "        self.labels_meniscus = labels_meniscus\n",
    "        self.exam_ids = exam_ids\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.indices = np.arange(len(self.exam_ids))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.exam_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        batch_exam_ids = [self.exam_ids[i] for i in batch_indices]\n",
    "        batch_slices, batch_labels_acl, batch_labels_meniscus = [], [], []\n",
    "        for exam_id in batch_exam_ids:\n",
    "            exam_path = os.path.join(self.data_dir, self.plane, f\"{exam_id}.npy\")\n",
    "            try:\n",
    "                volume = np.load(exam_path)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            label_acl = self.labels_acl.get(exam_id, None)\n",
    "            label_meniscus = self.labels_meniscus.get(exam_id, None)\n",
    "            if label_acl is None or label_meniscus is None:\n",
    "                continue\n",
    "            for i in range(volume.shape[0]):\n",
    "                slice_img = volume[i]\n",
    "                processed_slice = preprocess_slice(slice_img, self.target_size)\n",
    "                batch_slices.append(processed_slice)\n",
    "                batch_labels_acl.append(label_acl)\n",
    "                batch_labels_meniscus.append(label_meniscus)\n",
    "        batch_slices_np = np.array(batch_slices)\n",
    "        batch_labels_acl_np = np.array(batch_labels_acl, dtype=np.float32)\n",
    "        batch_labels_meniscus_np = np.array(batch_labels_meniscus, dtype=np.float32)\n",
    "        return batch_slices_np, {'acl_output': batch_labels_acl_np, 'meniscus_output': batch_labels_meniscus_np}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
